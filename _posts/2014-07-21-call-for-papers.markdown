---
layout: post
title:  "Call for Papers"
date:   2014-07-21 09:00:00
isStaticPost: false
---
Machine Learning for InformationManagement : Bridging Theory and Pratice
Workshop organised on 31stMay 2018 by Seth van Hooland, Anne
Chardonnens,Mathias Coeckelbergs, LaurenceMaroye and Ettore Rizza
Université libre de Bruxelles (ULB)
ReSIC Research Center
Information and Communication Science Department
Avenue F.D.Roosevelt 50 – CP123 – B-1050 Brussels, Belgium
Abstract
To what extent is the Information, Library and Archival Science community taking
Machine Learning (ML) at face value ? ML methods and tools for the classification,
clustering and indexing of documents have demonstrated tangible results
within cultural heritage institutions. As traditional indexing and cataloging practices
are increasingly pushed into a corner, reducing them to the luxury domain of
boutique metadata, the rise of ML techniques to face operational challenges has
been welcomed. However, how do we as a community assess the quality of the outcomes
of both supervised and unsupervised ML ? This workshop wishes to offer a
space to think for both researchers and practitioners to share ideas on how to redesign
and apply research evaluation methods to move the field forwards.
Context
MLmethods and tools are increasingly used to process large volumes of non-structured
documents, as has been underlined by institutions such as the National Archives
and Records Administration (1) and TheNational Archives (2). Various domains and
scientific disciplines, such as digital humanities, records management and archival
science, are either experimenting or implementing supervised and unsupervised
machine learning techniques. However, applying ML ressembles the act of throwing
mud at a wall : some of the results stick to the wall and deliver immediate operational
results, but it often is problematic to forecast results and assess what works
and what not. Also, when applying unsupervised machine learning approaches
to mine unstructured content for semantics, the outcomes may be leveraged with
Linked Data for disambiguation purposes. Even if the Linked Data paradigmhistorically
stems from a rules-based approach instead of relying on statistics, combining
both rules and statistics clearly offers opportunities for automated indexing. However,
relying on decentralised knowledge bases such asWikidata has its own difficulties
due to their broken-world character, where absent or conflicting data require a
permanent investment inmaintenance and repair (5).
In such a context, standard evaluation methods from the information retrieval
and computational linguistics community, such as calculating precision, recall and
F-score, are complex to apply. They often involve either overly deterministic computational
quality measurements or rely heavily on the subjective judgement of human
evaluators. The inherently problematic nature of how we define the quality of
1
information in an empirical context is not new and has been described by Isabelle
Boydens (4). The growing need to rely on ML as a documentation practice forces
us to not just launch an algorithm and accept the results at face value, but to both
conceptually and operationally question their quality.
The problematic nature of evaluating ML outcomes goes hand in hand with the
increasing complexity and sheer volume of corpora we have to manage. When patrons
deliver a copy of a shared drive with a chaotic folder structure or a decade
worth of emails from a server, archivist are increasingly struggling to apply macroappraisal,
as these fonds potentially contain records stemming from a multitude
of different functional contexts. However, as underlined by Anne J. Gilliland (3) in
the context of Archival Science, there is an increasing need to work with these dirty
real-life document sets instead of sterile, cleaned and marked up test sets which
are traditionally used for benchmarking purposes. However, how can we come up
with generalisable results, knowing that outcomes are very much dependent on a
specific corpus or document set ?
Agenda
The one-day event on Thursday 31st of May is split out over a hands-on morning
session and presentation of papers in the afternoon :
• Morning session :
– 09:00: Using LDA and W2V withMathias Coeckelbergs
– 10:45: Coffee break
– 11:00: Wikidata reconciliation with Ettore Rizza
– 12:30: Lunch break
• Afternoon session :
– 14:00: André Vellino (Information Studies,University ofOttowa): keynote
talk on researchmethodologies to evaluate the usage of ML
– 15:00: Mette Van Essen (Digital Advisor atNationaal ArchiefNetherlands):
experimental case-study to classify email with supervisedML
– 15:30: Coffee break
– 16:00: Graham McDonald (University of Glasgow School of Computing
Science): automatically classifying sensitive information in digital government
documents
– 16:30: Tan Lu and Ann Dooms (Digital Mathematics research group at
Vrije Universiteit Brussel): using supervised ML to spot quality issues in
digitised images of historical newspapers
– 17:00: Closing notes by Seth van Hooland (ULB) and drinks
Publication
The workshop will allow to bring together researchers to prepare contributions for
a Call for Papers to be launched in June 2018 in Cataloging and Classification Quarterly.
Participation
The event is sponsored thanks to the ULB Resic research group and the Belspofunded
projectHybrid Electronic Curation, Transformation andOrganization of Re-
2
cords (HECTOR). Participation is therefore free. However, as this workshop wants
to push forward the field and catalyse interaction between theory and practice, active
participation is required from the participants, both for the hands-on session
in the morning and during the discussion at the end of the afternoon session. People
wishing to attend should therefore motivate their participation in an email to
svhoolan@ulb.ac.be before May 1st 2018 and describe how their ongoing or future
activities map with the program.
Practical information
The workshop will take place on the ULB Solbosch campus. More practical information
in regards to the venu will be made available in the weeks to come on
http://mastic.ulb.ac.be.
References
[1] National Archives and Records Administration (NARA), Managing Government
Records Directive. Automated Electronic Records Management Plan, published
in September 2014 on https://www.archives.gov/records-mgmt/
prmd/automated-erm.html.
[2] The National Archives (TNA). Digital Strategy, published in April 2017 on
https://www.nationalarchives.gov.uk/documents/the-nationalarchives-
digital-strategy-2017-19.pdf.
[3] Anne J.Gilliland.Designing experts systems for archival evaluation and processing
of computer-mediated communications, Research in the ArchivalMultiverse,
2016, pages 686-722.
[4] Isabelle Boydens and Seth van Hooland. Hermeneutics applied to the quality of
empirical databases. Journal of documentation, 67, 2 (2011): pages 279-289.
[5] Daniel Lovins and Diane Hillmann. Broken-World Vocabularies. D-Lib Magazine,
March/April 2017, number 3/4, available on http://www.dlib.org/
dlib/march17/lovins/03lovins.html.
3